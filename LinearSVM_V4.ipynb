{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "import cv2\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.kernel_approximation import Nystroem\n",
    "from sklearn import svm\n",
    "from joblib import Parallel, delayed, cpu_count\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.feature import hog\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (15.0, 12.0)  # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "# plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading extenrnal modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (15.0, 12.0)  # set default size of plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"cache/training/neg_samples.pkl\", \"rb\") as f:\n",
    "    neg_samples = pickle.load(f)\n",
    "with open(\"cache/merged/waldo.pkl\", \"rb\") as f:\n",
    "    pos_waldo = pickle.load(f)\n",
    "with open(\"cache/merged/wenda.pkl\", \"rb\") as f:\n",
    "    pos_wenda = pickle.load(f)\n",
    "with open(\"cache/merged/wizard.pkl\", \"rb\") as f:\n",
    "    pos_wizard = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Compute HOG feature descriptor for all samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample image shape (128, 128), feature vector shape (24336,)\n",
      "Sample image shape (128, 128), feature vector shape (24336,)\n",
      "Sample image shape (128, 128), feature vector shape (24336,)\n",
      "Sample image shape (128, 128), feature vector shape (24336,)\n"
     ]
    }
   ],
   "source": [
    "# DESCRIPTOR CONFIG\n",
    "ORIENTATIONS_G = 9\n",
    "PIXELS_PER_CELL_G = (8,8)\n",
    "CELLS_PER_BLOCK_G = (4,4)\n",
    "ORIENTATIONS_C = 9\n",
    "PIXELS_PER_CELL_C = (8,8)\n",
    "CELLS_PER_BLOCK_C = (4,4)\n",
    "\n",
    "\n",
    "# viualize the descriptor once for each class\n",
    "for i, s in enumerate([pos_waldo[0], pos_wenda[0], pos_wizard[0], neg_samples[0]]):\n",
    "    feature, hog_image = hog(\n",
    "        s,\n",
    "        orientations=ORIENTATIONS_G,\n",
    "        pixels_per_cell=PIXELS_PER_CELL_G,\n",
    "        cells_per_block=CELLS_PER_BLOCK_G,\n",
    "        visualize=True,\n",
    "        multichannel=False,\n",
    "    )\n",
    "    print(\n",
    "        \"Sample image shape {}, feature vector shape {}\".format(s.shape, feature.shape)\n",
    "    )\n",
    "    plt.subplot(4, 2, 2 * i + 1)\n",
    "    plt.imshow(s)\n",
    "    plt.subplot(4, 2, 2 * i + 2)\n",
    "    plt.imshow(hog_image)\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_descriptor import describe\n",
    "\n",
    "LABELS = {\"waldo\": 0, \"wenda\": 1, \"wizard\": 2, \"negative\": 3}\n",
    "\n",
    "def feature_descriptor(samples, parallel=False):\n",
    "    res = None\n",
    "    if parallel:\n",
    "        res = Parallel(n_jobs=cpu_count())(\n",
    "            delayed(describe)(\n",
    "                s,\n",
    "                orientations_g=ORIENTATIONS_G,\n",
    "                pixels_per_cell_g=PIXELS_PER_CELL_G,\n",
    "                cells_per_block_g=CELLS_PER_BLOCK_G,\n",
    "                orientations_c=ORIENTATIONS_C,\n",
    "                pixels_per_cell_c=PIXELS_PER_CELL_C,\n",
    "                cells_per_block_c=CELLS_PER_BLOCK_C,\n",
    "            )\n",
    "            for s in samples\n",
    "        )\n",
    "    else:\n",
    "        res = [\n",
    "            describe(\n",
    "                s,\n",
    "                orientations_g=ORIENTATIONS_G,\n",
    "                pixels_per_cell_g=PIXELS_PER_CELL_G,\n",
    "                cells_per_block_g=CELLS_PER_BLOCK_G,\n",
    "                orientations_c=ORIENTATIONS_C,\n",
    "                pixels_per_cell_c=PIXELS_PER_CELL_C,\n",
    "                cells_per_block_c=CELLS_PER_BLOCK_C,\n",
    "            )\n",
    "            for s in samples\n",
    "        ]\n",
    "    return np.array(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform samples into feature space\n",
    "pf_wa = feature_descriptor(pos_waldo, parallel=True)\n",
    "pf_we = feature_descriptor(pos_wenda, parallel=True)\n",
    "pf_wi = feature_descriptor(pos_wizard, parallel=True)\n",
    "nf_s = feature_descriptor(neg_samples, parallel=True)\n",
    "\n",
    "X = np.concatenate((pf_wa, pf_we, pf_wi, nf_s), axis=0)\n",
    "Y = np.concatenate(\n",
    "    (\n",
    "        np.full(pf_wa.shape[0], LABELS[\"waldo\"]),\n",
    "        np.full(pf_we.shape[0], LABELS[\"wenda\"]),\n",
    "        np.full(pf_wi.shape[0], LABELS[\"wizard\"]),\n",
    "        np.full(nf_s.shape[0], LABELS[\"negative\"]),\n",
    "    ),\n",
    "    axis=0,\n",
    ")\n",
    "\n",
    "x_train, y_train = X, Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"training data shape: examples: {}, labels: {}\".format(x_train.shape, y_train.shape))\n",
    "\n",
    "pos = pf_wa.shape[0] + pf_we.shape[0] + pf_wi.shape[0]\n",
    "neg = nf_s.shape[0]\n",
    "tot = X.shape[0]\n",
    "\n",
    "print('waldo: {} {:2.2f}%'.format(pf_wa.shape[0], pf_wa.shape[0]*100/tot))\n",
    "print('wenda: {} {:2.2f}%'.format(pf_we.shape[0], pf_we.shape[0]*100/tot))\n",
    "print('wizard: {} {:2.2f}%'.format(pf_wi.shape[0], pf_wi.shape[0]*100/tot))\n",
    "print('negative: {} {:2.2f}%'.format(nf_s.shape[0], nf_s.shape[0]*100/tot))\n",
    "\n",
    "\n",
    "print('positive examples:\\t{}\\t{:2.2f}% \\nnegative examples\\t{}\\t{:2.2f}%'.format(pos, pos*100/tot, neg, neg*100/tot))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Train Support Vector Machine Classifier (SVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'C': [1e-3, 0.01, 0.1, 10, 100, 1000],\n",
    "    'gamma': [1e-4, 1e-3, 0.01, 0.1, 1, 10, 100],\n",
    "    'kernel': ['rbf', 'linear'],\n",
    "}\n",
    "\n",
    "\n",
    "print(x_train.shape, y_train.shape)\n",
    "\n",
    "# This uses hyperparameter search to find the best model.\n",
    "# Therefore it can be quite slow!\n",
    "#clf = GridSearchCV(svm.SVC(class_weight='balanced', decision_function_shape='ovo', random_state=0),\n",
    "#                  param_grid, refit=True, n_jobs=-1, cv=5)\n",
    "\n",
    "clf = svm.SVC(C=100, gamma=0.01, kernel='rbf', class_weight='balanced', random_state=0, decision_function_shape='ovo', probability=False, verbose=True)\n",
    "\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "#print('best parameters:')\n",
    "#print(clf.best_params_)\n",
    "#print(clf.best_estimator_)\n",
    "\n",
    "# save model to disk\n",
    "with open(\"./Linear_SVM_V4.pkl\", \"wb\") as f:\n",
    "    pickle.dump(clf, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Evaluate Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load testing data\n",
    "with open(\"cache/testing/waldo.pkl\", \"rb\") as f:\n",
    "    test_waldo = pickle.load(f)\n",
    "with open(\"cache/testing/wenda.pkl\", \"rb\") as f:\n",
    "    test_wenda = pickle.load(f)\n",
    "with open(\"cache/testing/wizard.pkl\", \"rb\") as f:\n",
    "    test_wizard = pickle.load(f)\n",
    "with open(\"cache/testing/neg_samples.pkl\", \"rb\") as f:\n",
    "    test_neg_samples = pickle.load(f)[:20]\n",
    "\n",
    "# transform samples into feature space\n",
    "test_waldo = feature_descriptor(test_waldo, parallel=True)\n",
    "test_wenda = feature_descriptor(test_wenda, parallel=True)\n",
    "test_wizard = feature_descriptor(test_wizard, parallel=True)\n",
    "test_neg_samples = feature_descriptor(test_neg_samples, parallel=True)\n",
    "\n",
    "x_test = np.concatenate((test_waldo, test_wenda, test_wizard, test_neg_samples), axis=0)\n",
    "y_test = np.concatenate(\n",
    "    (\n",
    "        np.full(test_waldo.shape[0], LABELS[\"waldo\"]),\n",
    "        np.full(test_wenda.shape[0], LABELS[\"wenda\"]),\n",
    "        np.full(test_wizard.shape[0], LABELS[\"wizard\"]),\n",
    "        np.full(test_neg_samples.shape[0], LABELS[\"negative\"]),\n",
    "    ),\n",
    "    axis=0,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, clf.predict(x_test),\n",
    "                           target_names=LABELS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_pred = clf.predict(x_test)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "ax = plt.subplot()\n",
    "ax.imshow(conf_matrix, interpolation='nearest')\n",
    "ax.set(xticks=np.arange(conf_matrix.shape[1]),\n",
    "       yticks=np.arange(conf_matrix.shape[0]),\n",
    "       xticklabels=LABELS, yticklabels=LABELS,\n",
    "       ylabel='True label',\n",
    "       xlabel='Predicted label')\n",
    "plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "         rotation_mode=\"anchor\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Try the classifier on one sample image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('cache/waldo45.pkl', 'rb') as f:\n",
    "    sample = pickle.load(f)\n",
    "    \n",
    "with open('./Linear_SVM_V3_KMeans.pkl', 'rb') as f:\n",
    "    kmeans = pickle.load(f)\n",
    "    K = 5\n",
    "    \n",
    "def recreate_image(codebook, labels, w, h):\n",
    "    \"\"\"Recreate the (compressed) image from the code book & labels\"\"\"\n",
    "    d = codebook.shape[1]\n",
    "    image = np.zeros((w, h, d), dtype=np.uint8)\n",
    "    label_idx = 0\n",
    "    for i in range(w):\n",
    "        for j in range(h):\n",
    "            image[i,j] = codebook[labels[label_idx]]\n",
    "            label_idx += 1\n",
    "    return image\n",
    "\n",
    "def process_img(img):\n",
    "    w,h,d = img.shape\n",
    "    labels = kmeans.predict(np.reshape(img, (w*h,d)))\n",
    "    \n",
    "    white_idx =  np.argmin([np.linalg.norm(np.array([253, 253, 253]) - c) for c in kmeans.cluster_centers_])\n",
    "    other_col_idx = np.argmin([np.linalg.norm(np.array([182,159,154]) - c) for c in kmeans.cluster_centers_])\n",
    "    labels[labels == other_col_idx] = white_idx\n",
    "    \n",
    "    c = (np.arange(0,K) * 255 / (K-1)).astype(np.uint8)[np.newaxis].T\n",
    "    cluster_centers = np.hstack([c,c,c])\n",
    "    return recreate_image(cluster_centers, labels, w,h)[:,:,0]\n",
    "\n",
    "img = sample['img']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bbx_iou(bbx1, bbx2):\n",
    "    if bbx1[0] >= bbx1[2] or bbx1[1] >= bbx1[3] or bbx2[0] >= bbx2[2] or bbx2[1] >= bbx2[3]:\n",
    "        return 0\n",
    "    \n",
    "    # determine the coordinates of the intersection rectangle\n",
    "    x_left = max(bbx1[0], bbx2[0])\n",
    "    y_top = max(bbx1[1], bbx2[1])\n",
    "    x_right = min(bbx1[2], bbx2[2])\n",
    "    y_bottom = min(bbx1[3], bbx2[3])\n",
    "    \n",
    "    if x_right < x_left or y_bottom < y_top:\n",
    "        return 0.0\n",
    "\n",
    "    # The intersection of two axis-aligned bounding boxes is always an\n",
    "    # axis-aligned bounding box\n",
    "    intersection_area = (x_right - x_left) * (y_bottom - y_top)\n",
    "    \n",
    "    # compute the area of both AABBs\n",
    "    bbx1_area = (bbx1[2] - bbx1[0]) * (bbx1[3] - bbx1[1])\n",
    "    bbx2_area = (bbx2[2] - bbx2[0]) * (bbx2[3] - bbx2[1])\n",
    "    \n",
    "    # compute the intersection over union by taking the intersection\n",
    "    # area and dividing it by the sum of prediction + ground-truth\n",
    "    # areas - the interesection area\n",
    "    iou = intersection_area / float(bbx1_area + bbx2_area - intersection_area)\n",
    "    assert iou >= 0.0\n",
    "    assert iou <= 1.0\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_max_suppression(detections, threshold=0.0):\n",
    "    groups = [[detections[0]]]\n",
    "    for d in detections:\n",
    "        n_groups = groups.copy()\n",
    "        for idx, g in enumerate(groups):\n",
    "            if np.max([bbx_iou(d[:4], bbx[:4]) for bbx in g]) > threshold:\n",
    "                n_groups[idx].append(d)\n",
    "            else:\n",
    "                n_groups.append([d])\n",
    "            break\n",
    "        groups = n_groups\n",
    "        \n",
    "    #print(np.array(groups))\n",
    "        \n",
    "    detections = []\n",
    "    for g in groups:\n",
    "        detections.append(g[np.argmax(x[-1] for x in g)])\n",
    "    return detections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img = cv2.cvtColor(cv2.imread(\"datasets/JPEGImages/018.jpg\"), cv2.COLOR_BGR2RGB)\n",
    "def draw_bbox(ax, name, box, col='r'):\n",
    "    r = patches.Rectangle((box[0], box[1]), \n",
    "                          box[2] - box[0],\n",
    "                          box[3] - box[1],\n",
    "                          linewidth=3,\n",
    "                          edgecolor=col,\n",
    "                          facecolor='none')\n",
    "    ax.add_patch(r)\n",
    "    ax.text(box[0], box[1], name,\n",
    "            bbox={'facecolor': col, 'linewidth': 0})\n",
    "\n",
    "def draw_annotation(ax, classes):\n",
    "    for idx, cl in enumerate(classes):\n",
    "        col = 'g'\n",
    "        for box in cl['bounds']:\n",
    "            draw_bbox(ax, cl['name'], box, col)\n",
    "\n",
    "def dict_invert(key, d):\n",
    "    return set(k for k, v in d.items() if v == key).pop()\n",
    "\n",
    "\n",
    "def _transform_feature(img, ymin, ymax, xmin, xmax):\n",
    "    if np.var(np.random.choice(img[ymin:ymax, xmin:xmax, 0].ravel(), 500)) < 5000:\n",
    "        return (0,0,0,0, None)\n",
    "    window = cv2.resize(img[ymin:ymax, xmin:xmax], dsize=(128, 128), interpolation=cv2.INTER_LINEAR)\n",
    "    return (ymin, ymax, xmin, xmax, feature_descriptor([process_img(window)]))\n",
    "\n",
    "def _predict(ymin, ymax, xmin, xmax, feat_vect):\n",
    "    if feat_vect is None:\n",
    "        return None\n",
    "    \n",
    "    label = clf.predict(feat_vect)\n",
    "    \n",
    "    if LABELS['negative'] not in label:\n",
    "        #proba = clf.predict_proba(feat_vect)[0]\n",
    "        #p_ratio = proba[label[0]] / np.sort(proba)[-2]\n",
    "        proba = [1,1,1,1,1]\n",
    "        p_ratio = 1\n",
    "        \n",
    "        print(ymin, ymax, xmin, xmax, dict_invert(label[0], LABELS), proba[label[0]], p_ratio)\n",
    "        return [ymin, ymax, xmin, xmax, label, p_ratio]\n",
    "    return []\n",
    "\n",
    "def detect_img(img):\n",
    "    img_y, img_x = img.shape[:2]\n",
    "    size = 128\n",
    "    print('performing detection on image of size {} with window size {}'.format(img.shape, size))\n",
    "        \n",
    "    with mp.Pool(mp.cpu_count()) as p:\n",
    "        args = []\n",
    "        for scale in range(1, 6):\n",
    "            window_size = size * scale\n",
    "            for y in range(0, img_y - window_size, window_size // 4):\n",
    "                for x in range(0, img_x - window_size, window_size // 4):\n",
    "                    args.append((img, y, y + window_size, x, x + window_size))\n",
    "\n",
    "        print(\"transforming image windows into feature space\")\n",
    "\n",
    "        feature_vectors = p.starmap(_transform_feature, args)\n",
    "\n",
    "        print('... done')\n",
    "        print(\"detecting classes for windows\")\n",
    "        print('detections:')\n",
    "        \n",
    "        detections = p.starmap(_predict, feature_vectors)\n",
    "        \n",
    "        \n",
    "        omitted = 0\n",
    "        detections_ = []\n",
    "        for d in detections:\n",
    "            if d: detections_.append(d)\n",
    "            elif d is None: omitted += 1\n",
    "        detections = detections_   \n",
    "\n",
    "            \n",
    "    #print('median confidence {}%'.format(np.median(confidence, axis = 0)*100))\n",
    "    \n",
    "    print('omitted {:2f}% of windows'.format(omitted / len(feature_vectors)*100))\n",
    "    print('evaluated {} windows'.format(len(feature_vectors)))\n",
    "    \n",
    "    #detections = non_max_suppression(detections)\n",
    "    print('num classes after non_max_supp: {}'.format(len(detections)))\n",
    "    \n",
    "    ax = plt.subplot(1, 1, 1)\n",
    "    plt.imshow(img)\n",
    "    # draw gound truth\n",
    "    #draw_annotation(ax, sample['classes'])\n",
    "\n",
    "    # draw detections\n",
    "    for d in detections:\n",
    "        w, h = d[3] - d[2], d[1] - d[0]\n",
    "        p = patches.Rectangle((d[2], d[0]), w, h, edgecolor=\"r\", facecolor=\"none\", linewidth=3)\n",
    "        ax.text(d[2], d[0], '{}: {:2.1f}'.format(dict_invert(d[4], LABELS), d[5]),\n",
    "            bbox={'facecolor': 'r', 'linewidth': 0},\n",
    "           fontsize='small')\n",
    "        ax.add_patch(p)\n",
    "        \n",
    "    plt.show()\n",
    "    return np.array(detections)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with open('cache/waldo45.pkl', 'rb') as f:\n",
    "    sample = pickle.load(f)\n",
    "    \n",
    "\n",
    "start = time.perf_counter()   \n",
    "detect_img(sample['img'])\n",
    "\n",
    "print('elapsed time {} s'.format(time.perf_counter() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with open('cache/waldo29.pkl', 'rb') as f:\n",
    "    sample = pickle.load(f)\n",
    "\n",
    "start = time.perf_counter()   \n",
    "detect_img(sample['img'])\n",
    "\n",
    "print('elapsed time {} s'.format(time.perf_counter() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with open('cache/waldo48.pkl', 'rb') as f:\n",
    "    sample = pickle.load(f)\n",
    "    \n",
    "start = time.perf_counter()   \n",
    "detect_img(sample['img'])\n",
    "\n",
    "print('elapsed time {} s'.format(time.perf_counter() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with open('cache/waldo3.pkl', 'rb') as f:\n",
    "    sample = pickle.load(f)\n",
    "    \n",
    "start = time.perf_counter()   \n",
    "detect_img(sample['img'])\n",
    "\n",
    "print('elapsed time {} s'.format(time.perf_counter() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with open('cache/waldo39.pkl', 'rb') as f:\n",
    "    sample = pickle.load(f)\n",
    "    \n",
    "start = time.perf_counter()   \n",
    "detect_img(sample['img'])\n",
    "\n",
    "print('elapsed time {} s'.format(time.perf_counter() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescale(img, min_size=2048, max_size=4096):\n",
    "    h,w = img.shape[:2]\n",
    "    if max(h,w) > max_size:\n",
    "        if w > h:\n",
    "            dsize = (max_size, int(h * max_size / w))\n",
    "        else:\n",
    "            dsize = (int(w * max_size / h), max_size)\n",
    "    elif min(h,w) < min_size:\n",
    "        if w > h:\n",
    "            dsize = (int(w * min_size / h), min_size)\n",
    "        else:\n",
    "            dsize = (min_size, int(h * min_size / w))\n",
    "\n",
    "    return cv2.resize(img, dsize=dsize, interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "#img = cv2.cvtColor(cv2.imread('datasets/JPEGImages/003.jpg'), cv2.COLOR_BGR2RGB)\n",
    "#print(img.shape)\n",
    "#print(rescale(img).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "val_imgs = ['003', '043','038', '056', '067', '074', '018', '036']\n",
    "for name in val_imgs:  \n",
    "    path = 'datasets/JPEGImages/{}.jpg'.format(name)\n",
    "    print('loading img: {}'.format(path))\n",
    "\n",
    "    img = cv2.cvtColor(cv2.imread(path), cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    start = time.perf_counter()\n",
    "    img = rescale(img)\n",
    "    detect_img(img)\n",
    "    print('elapsed time {} s'.format(time.perf_counter() - start))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python [conda env:cvpr] *",
   "language": "python",
   "name": "conda-env-cvpr-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
