\documentclass[11pt]{article}
\usepackage[OT4]{fontenc}
\newtheorem{define}{Definition}
\usepackage{graphicx}
\usepackage{subcaption}
\oddsidemargin=0.15in
\evensidemargin=0.15in
\topmargin=-.5in
\textheight=9in
\textwidth=6.25in

\begin{document}
	
\input{preamble.tex}
\header{Maximilian Fruehauf, David Drews, Choo Wen Xin}{Where's Waldo Detector using Computer Vision}
\begin{abstract}
This report describes our group's implementation of a computer vision algorithm to detect Waldo, Wenda, and the Wizard from a series of "Where's Waldo" books. The goal of this project is to detect the three characters from the provided high-resolution images, which can be very complex with a lot of detail and many other characters. The three characters also may or may not appear in any given image.\\

Due to the complex nature of the given images, and variation of the characters' appearances, detecting the characters accurately proved to be a challenge. In some cases, we could not identify where the characters are, and a lot of false positives were present as well.\\

Our proposed solution is to use a histogram over gradients (HoG) feature descriptor, then training a linear support vector machine (SVM) to create our classifier. We were able to detect some instances of Waldo, espcially in the postcard in the top left hand corner of the page.


\end{abstract}
%%%% body goes in here %%%%
\section{Introduction}
"Where's Waldo" is a series of books containing detailed, high-resolution illustrations. For this project, we are given a set of scanned images from the book, and are tasked to design a computer vision algorithm that can detect the three characters from the book: Waldo, Wenda, and the Wizard. Each image may contain one or more of these characters. We are provided with a set of training images with annotations of the bounding box locations of Waldo, Wenda, or the Wizard in each image.\\

Throughout the course of the project, we have attempted several different methods with varying degrees of success. While there are several existing computer vision algorithms for face and object detection, such as the "You Only Look Once" object detection~\cite{redmon2016yolo}, these do not seem to work too well with illustrated characters like Waldo, in a complex illustrated iamge. The characters' appearance and size also seems to vary across images, sometimes only a smaller part of the character (i.e a part of the face) is visible. This makes identifying the characters more challenging as well.\\

Across all approaches, we've only been working with the data that was handed to us as part of the assignment. Although our code alters the given data wherever needed, we did neither add any entirely new data from sources like the internet nor did we manually improve the existing data as could be achieved by adding or improving annotations.\\

The data we utilised can be summarised as follows:

\begin{itemize}
    \item 80 high resolution images from the \textit{Where's Waldo} book series
    \item 137 images of Waldo cropped to the patch of the image as describe in the annotation files
    \item 43 images of Wenda cropped to the patch of the image as describe in the annotation files
    \item 27 images of Wizard cropped to the patch of the image as describe in the annotation files
    \item Approximately 14,000 to 15,000 images (128x128px) subsampled from the original images, which did neither contain Waldo, Wenda or Wizard, used as negative training samples
\end{itemize}

In order to assess the performance of our algorithms we split the given set of images in a training and a testing set. This reduced the amount of positive samples of the three characters to 124 training samples for Waldo, 36 for Wenda and 24 for Wizard. As we will discuss in the upcoming sections, this uneaven split of training samples influenced the performance of our solution for the three different classes. 

We proposed using a few methods:

\begin{itemize}
    \item histogram over gradients (HoG) feature descriptor
    \item training a linear support vector machine (SVM) to create a multiclass-classifier
\end{itemize}

We will discuss our proposed solution in the next section.\\


\section{Proposed Solution}
Give an overview of your solution, put it in a framework. Then, detail each part in the framework.

\begin{figure}[ht]
\centering
    \includegraphics[width=14cm]{figures/coteaching.png}
    \caption{Our proposed solution.}
    \label{fig:framework}
\end{figure}


\section{Experiments}
\subsection{Data Preparation and Configuration}


Specify how to process the data, how to evaluate the performance (e.g., mAP).
\begin{table}[ht]
    \centering
    \begin{tabular}{l|c|c|c}
    \hline
     Dataset & \#train & \#test & \#Category\\
    \hline
    MNIST& 60,000 & 10,000 & 10  \\
    CIFAR-10& 50,000 & 10,000 & 10 \\
    \hline
    \end{tabular}
    \caption{Summary of datasets.}
    \label{tab:dataset}
\end{table}

\subsection{Implementation}
Give a figure to illustrate your implementation, then detail each parts.

\subsection{Results}
Present the results, both qualitatively (visualize) and quantitatively (specific numbers)..
Analyze the results
\subsection{Discussion}
Strengths and weakness in your method.

\section{Conclusion}
In this project, we ...

\section{Group Information}
\begin{table*}[ht]
    \centering
    \begin{tabular}{l|c|c|c}
    \hline
     Member & Student ID & Email & Contribution\\
    \hline
    Maximilian Fruehauf& Axx & e0445541@u.nus.edu & xxx \\
    David Drews& Axx &e0454245@u.nus.edu & xxx  \\
    Choo Wen Xin& A0160465H & e0053347@u.nus.edu & xxx  \\
    \hline
    \end{tabular}
    \caption{Group member information.}
    \label{tab:dataset}
\end{table*}
\bibliographystyle{plain}

\bibliography{references}
 
\end{document}




